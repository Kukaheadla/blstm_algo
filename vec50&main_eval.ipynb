{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bi-directional LSTM: Machine Learning\n",
    "\n",
    "## Description of text features\n",
    "\n",
    "This notebook describes the pre-computed text features provided for assignment 2. **You do not need to recompute the features yourself for this assignment** -- this information is just for your reference. However, feel free to experiment with different text features if you are interested. If you do want to try generating your own text features, some things to keep in mind:\n",
    "- There are many different decisions you can make throughout the feature design process, from the text preprocessing to the size of the output vectors. There's no guarantee that the defaults we chose will produce the best possible text features for this classification task, so feel free to experiment with different settings.\n",
    "- These features must be trained on a training corpus. Generally, the training corpus should not include validation samples, but for the purposes of this assignment we have used the entire non-test set (training+validation) as the training corpus, to allow you to experiment with different validation sets. If you recompute the text features as part of your own model, you should exclude validation samples and retrain on training samples only. Note that if you do N-fold cross-validation, this means generating N sets of features for N different training-validation splits.\n",
    "- This code may take a long time to run and require a good bit of memory, which is why we are not requiring you to recompute these features yourself. doc2vec in particular is very slow unless you can implement some speed-ups in C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import TruncatedSVD, PCA\n",
    "\n",
    "from sklearn import linear_model, naive_bayes\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, train_test_split\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Seed variable used in random_state\n",
    "SEED_NO = 0\n",
    "\n",
    "# read text\n",
    "# for DEMONSTRATION PURPOSES, the entire training set will be used to train the models and also as a test set\n",
    "X_train_original = pd.read_csv(r\"./COMP30027_2021_Project2_datasets/recipe_train.csv\", index_col = False, delimiter = ',', header=0)\n",
    "# use recipe name as an example\n",
    "train_corpus_name = X_train_original['name']\n",
    "test_name = X_train_original['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_train_original Dimensions:', X_train_original.shape)\n",
    "print(\"train_corpus_name Dimensions:\", train_corpus_name.shape)\n",
    "print(\"y_train Dimensions:\", X_train_original.duration_label.shape)\n",
    "print(\"Attributes Names: {}\".format(X_train_original.columns.values))\n",
    "X_train_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using pre-existing doc2Vec50 files\n",
    "X_train_name = pd.read_csv(r\"./COMP30027_2021_Project2_datasets/recipe_text_features_doc2vec50/train_name_doc2vec50.csv\", \n",
    "            index_col = False, \n",
    "            delimiter = ',', \n",
    "            header=None)\n",
    "\n",
    "X_train_steps = pd.read_csv(r\"./COMP30027_2021_Project2_datasets/recipe_text_features_doc2vec50/train_steps_doc2vec50.csv\", \n",
    "            index_col = False, \n",
    "            delimiter = ',', \n",
    "            header=None)\n",
    "            \n",
    "X_train_ingr = pd.read_csv(r\"./COMP30027_2021_Project2_datasets/recipe_text_features_doc2vec50/train_ingr_doc2vec50.csv\", \n",
    "            index_col = False, \n",
    "            delimiter = ',', \n",
    "            header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_name = pd.read_csv(r\"./COMP30027_2021_Project2_datasets/recipe_text_features_doc2vec50/test_name_doc2vec50.csv\", \n",
    "            index_col = False, \n",
    "            delimiter = ',', \n",
    "            header=None)\n",
    "\n",
    "X_test_steps = pd.read_csv(r\"./COMP30027_2021_Project2_datasets/recipe_text_features_doc2vec50/test_steps_doc2vec50.csv\", \n",
    "            index_col = False, \n",
    "            delimiter = ',', \n",
    "            header=None)\n",
    "            \n",
    "X_test_ingr = pd.read_csv(r\"./COMP30027_2021_Project2_datasets/recipe_text_features_doc2vec50/test_ingr_doc2vec50.csv\", \n",
    "            index_col = False, \n",
    "            delimiter = ',', \n",
    "            header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Set of Duration Labels: \" , set(X_train_original.duration_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estbalish a Feature & Label dataframe for graphing purposes \n",
    "vectorized_df = pd.concat([X_train_name, X_train_steps, X_train_ingr, X_train_original.duration_label], axis=1)\n",
    "vectorized_df.duration_label = vectorized_df.duration_label.astype(str) #For graphing putpose, so lengend will show it as discrete value\n",
    "vectorized_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_reduced = vectorized_df #creates a copy used for dimensionality reduction \n",
    "\n",
    "#To showcase that there are no distinct clusters through after PCA transformation on number vectors\n",
    "sc = StandardScaler()\n",
    "pca = PCA(n_components=3, random_state=SEED_NO)\n",
    "components = pca.fit_transform(sc.fit_transform(tokenized_reduced))\n",
    "labels = {\n",
    "    str(i): f\"PCA {i+1} ({var:.1f}%)\" for i, var in enumerate(pca.explained_variance_ratio_ * 100)\n",
    "} \n",
    "\n",
    "#Representing Single Value Decomposition in Low Dimension Settings\n",
    "fig = px.scatter_matrix(components, \n",
    "                        labels=labels, \n",
    "                        dimensions=range(pca.components_.shape[0]), \n",
    "                        color=tokenized_reduced.duration_label,\n",
    "                        title=\"Total Explained Ratio (R-Sq): {:.2f}%\".format(pca.explained_variance_ratio_.sum()*100),\n",
    "                        width=800, height=500\n",
    "                       ).update_traces(diagonal_visible=False, marker=dict(size=3))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA to see reduction aids in better total explanability\n",
    "tokenized_pca = PCA().fit(sc.fit_transform(tokenized_reduced))\n",
    "\n",
    "# Looking at the R-Squared Slopes\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=np.arange(tokenized_pca.n_components_+1),\n",
    "                         y=tokenized_pca.explained_variance_ratio_, \n",
    "                         mode='lines',\n",
    "                         name='R-squared'))\n",
    "fig.add_trace(go.Scatter(x=np.arange(tokenized_pca.n_components_+1),\n",
    "                         y=np.cumsum(tokenized_pca.explained_variance_ratio_), \n",
    "                         mode='lines',\n",
    "                         name='Accumulative R-Squared'))\n",
    "fig.update_layout(title='R-Squared vs. No. of PCA Components',\n",
    "                  xaxis_title='Principal Component No.',\n",
    "                  yaxis_title='R-Squared Value')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = X_train_original.duration_label\n",
    "\n",
    "# Modelling Linear Classifier to be used within benchmarks\n",
    "print(\"--- \\nMulti-class Logistic Regression \")\n",
    "LR_clf = linear_model.LogisticRegression(random_state=SEED_NO,\n",
    "                                         C=0.9, \n",
    "                                         max_iter = 50000,\n",
    "                                         multi_class='multinomial')\n",
    "\n",
    "# Compute Cross_validation score usign 5-fold and average the accuracy for each CSV files (parallel processing)\n",
    "LR_accuracy = (cross_val_score(LR_clf, X_train_name, y_train, cv=5).mean() + \\\n",
    "        cross_val_score(LR_clf, X_train_steps, y_train, cv=5).mean() + \\\n",
    "        cross_val_score(LR_clf, X_train_ingr, y_train, cv=5).mean()) / 3\n",
    "print(\"Multinomial Logistic Regression Accuracy:\", LR_accuracy)\n",
    "\n",
    "print(\"--- \\nMultinomial Naive Bayes\")\n",
    "NB_clf = naive_bayes.GaussianNB()\n",
    "NB_accuracy = (cross_val_score(NB_clf, X_train_name, y_train, cv=5).mean() + \\\n",
    "        cross_val_score(NB_clf, X_train_steps, y_train, cv=5).mean() + \\\n",
    "        cross_val_score(NB_clf, X_train_ingr, y_train, cv=5).mean()) / 3\n",
    "print(\"Multinomial NB Accuracy\", NB_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import tensorflow.keras.utils as utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, LSTM, Bidirectional\n",
    "\n",
    "#Stacking all Vectorized feature and reshape them into  3-D Array\n",
    "X_train_3dim = np.hstack((X_train_ingr, X_train_name, X_train_steps))\n",
    "X_train_3dim = np.reshape(X_train_3dim, (X_train_3dim.shape[0], 1, X_train_3dim.shape[1]))\n",
    "print(\"Transformed X_train Dimensions:          \", X_train_3dim.shape)\n",
    "\n",
    "# One-hot Encoding for Y_train\n",
    "y_train_le = LabelEncoder().fit_transform(y_train)\n",
    "y_train_onehot = utils.to_categorical(y_train_le)\n",
    "print(\"One-hot Encoding Dimensions for y_train: \", y_train_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bidirectional_LSTM_clf(X, y, epochs_size, batch_size):\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(X.shape[2], return_sequences=True, dropout=0.4, input_shape=(1, X.shape[2]))))\n",
    "    model.add(Bidirectional(LSTM(X.shape[2], return_sequences=False, dropout=0.4, input_shape=(1, X.shape[2]))))\n",
    "    model.add(Dense(X.shape[2], activation='tanh'))\n",
    "    model.add(Dense(3, activation='softmax')) #Softmax output for 3 corresponding categorical variables\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model_history = model.fit(X, y, \n",
    "                            epochs=epochs_size, \n",
    "                            batch_size=batch_size, \n",
    "                            validation_split=0.2,\n",
    "                            verbose=1)\n",
    "    return model, model_history \n",
    "\n",
    "bi_lstm_model, bi_lstm_model_history = Bidirectional_LSTM_clf(X_train_3dim, y_train_onehot, 10, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm_model.summary()\n",
    "# print(\"LSTM Model Training Acccuracy:                        {:.2f}\".format(lstm_model_history.history['accuracy'][-1]))\n",
    "# print(\"LSTM Model Cross-Validation Acccuracy:                {:.2f}\".format(lstm_model_history.history['val_accuracy'][-1]))\n",
    "# print(\"-----------------------------------------------------------------\\n\")\n",
    "bi_lstm_model.summary()\n",
    "print(\"Bidirectional LSTM Model Training Acccuracy:          {:.2f}\".format(bi_lstm_model_history.history['accuracy'][-1]))\n",
    "print(\"Bidirectional LSTM Model Cross-Validation Acccuracy:  {:.2f}\".format(bi_lstm_model_history.history['val_accuracy'][-1]))\n",
    "# bi_lstm_model_history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot line for epoch and loss function\n",
    "acc_df = pd.DataFrame(\n",
    "            zip(np.arange(60), \n",
    "                # lstm_model_history.history['accuracy'],  \n",
    "                bi_lstm_model_history.history['accuracy'],\n",
    "                # lstm_model_history.history['val_accuracy'],  \n",
    "                bi_lstm_model_history.history['val_accuracy']\n",
    "                ),\n",
    "            columns=[\"Epoch Iteration\", \n",
    "                    # \"LSTM Model (Training)\", \n",
    "                    \"Bidirectional LSTM Model (Training)\",\n",
    "                    # \"LSTM Model (Cross Validation)\",\n",
    "                    \"Bidirectional LSTM Model (Cross Validation)\",\n",
    "                    ],\n",
    "            )\n",
    "\n",
    "loss_df = pd.DataFrame(\n",
    "            zip(np.arange(60), \n",
    "                # lstm_model_history.history['loss'],  \n",
    "                bi_lstm_model_history.history['loss'],\n",
    "                # lstm_model_history.history['val_loss'],  \n",
    "                bi_lstm_model_history.history['val_loss']\n",
    "                ),\n",
    "            columns=[\"Epoch Iteration\", \n",
    "                    # \"LSTM Model (Training)\", \n",
    "                    \"Bidirectional LSTM Model (Training)\",\n",
    "                    # \"LSTM Model (Cross Validation)\",\n",
    "                    \"Bidirectional LSTM Model (Cross Validation)\",\n",
    "                    ],\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=1, cols=2,\n",
    "                    subplot_titles=[\"Accuracy per Epoch Iteration\", \"Loss per Epoch Iteration\"])\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=acc_df['Epoch Iteration'], y=acc_df[\"Bidirectional LSTM Model (Training)\"], \n",
    "                name=\"Bidirectional LSTM Model (Training)\", legendgroup='group2', line_color='purple'),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=acc_df['Epoch Iteration'], y=acc_df[\"Bidirectional LSTM Model (Cross Validation)\"], \n",
    "                name=\"Bidirectional LSTM Model (Cross Validation)\", legendgroup='group4', line_color='red'),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=loss_df['Epoch Iteration'], y=loss_df[\"Bidirectional LSTM Model (Training)\"], \n",
    "                name=\"Bidirectional LSTM Model (Training)\", legendgroup='group2', line_color='purple', showlegend = False),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=loss_df['Epoch Iteration'], y=loss_df[\"Bidirectional LSTM Model (Cross Validation)\"], \n",
    "                name=\"Bidirectional LSTM Model (Cross Validation)\", legendgroup='group4', line_color='red', showlegend = False), \n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(height=600, width=1000, title_text=\"Accuracy & Loss per Epoch Iterations\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction based on Remaining Discrete Data \n",
    "\n",
    "No. of Ingredients, No. of Steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_discrete =  X_train_original[['n_steps', 'n_ingredients']]\n",
    "X_train_discrete.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_df = X_train_discrete.join(y_train)\n",
    "scatter_df.duration_label = scatter_df.duration_label.astype(str)\n",
    "px.scatter(scatter_df, x=\"n_steps\", y=\"n_ingredients\", color=\"duration_label\", title=\"No. of Cooking Steps vs. No. of Ingredients\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_voting_scoring(clf, X_train_name, X_train_steps, X_train_ingr, y_train):\n",
    "    y_pred_name = cross_val_predict(clf, X_train_name, y_train, cv=5)\n",
    "    y_pred_steps = cross_val_predict(clf, X_train_steps, y_train, cv=5)\n",
    "    y_pred_ingr = cross_val_predict(clf, X_train_ingr, y_train, cv=5)\n",
    "\n",
    "    y_pred_pool = pd.DataFrame({\"name\": y_pred_name, \"steps\": y_pred_steps, \"ingr\": y_pred_ingr})\n",
    "    # # Return mode of label (the majority) in row-wise comparison\n",
    "    return y_pred_pool.mode(axis=1)[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict relevant data\n",
    "y_pred_NB = majority_voting_scoring(NB_clf, X_train_name, X_train_steps, X_train_ingr, y_train)\n",
    "y_pred_LR = majority_voting_scoring(LR_clf, X_train_name, X_train_steps, X_train_ingr, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert one-hot label output back to one of {1, 2, 3}\n",
    "y_pred_BLSTM = np.array(list(map(lambda x: float(x+1), # Increment output to match category as np.argmax return position of one-hot array\n",
    "                        np.argmax(bi_lstm_model.predict(X_train_3dim), axis=-1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report for Naive Bayes & Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names =['1.0', '2.0', '3.0']\n",
    "\n",
    "print(\"----------- Naive Bayes Classifier Report -----------\")\n",
    "# print(\"Accuracy Score: \", accuracy_score(y_train.astype(str), y_pred_NB.astype(str)))\n",
    "print(classification_report(y_train.astype(str), y_pred_NB.astype(str), target_names=target_names, digits=4))\n",
    "print(\"------- Logistic Regression Classifier Report -------\")\n",
    "# print(\"Accuracy Score: \", accuracy_score(y_train.astype(str), y_pred_LR.astype(str)))\n",
    "print(classification_report(y_train.astype(str), y_pred_LR.astype(str), target_names=target_names, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train_name, X_train_steps, X_train_ingr], axis=1)\n",
    "\n",
    "#Split the data to test for LSTM accuracy \n",
    "X_train_lstm, X_test_lstm, y_train_lstm, y_test_lstm = train_test_split(X_train, y_train, test_size=0.3, random_state=SEED_NO)\n",
    "\n",
    "# #Stacking all Vectorized feature and reshape them into  3-D Array\n",
    "X_train_3dim = np.reshape(np.array(X_train_lstm), newshape=(X_train_lstm.shape[0], 1, X_train_lstm.shape[1]))\n",
    "X_test_3dim = np.reshape(np.array(X_test_lstm), newshape=(X_test_lstm.shape[0], 1, X_test_lstm.shape[1]))\n",
    "print(\"Transformed X_train Dimensions:          \", X_train_3dim.shape)\n",
    "\n",
    "# One-hot Encoding for Y_train\n",
    "y_train_le = LabelEncoder().fit_transform(y_train_lstm)\n",
    "y_train_onehot = utils.to_categorical(y_train_le)\n",
    "print(\"One-hot Encoding Dimensions for y_train: \", y_train_onehot.shape)\n",
    "\n",
    "bi_lstm_model, bi_lstm_model_history = Bidirectional_LSTM_clf(X_train_3dim, y_train_onehot, 10, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"------- Bidirectional LSTM Classifier Report -------\")\n",
    "y_pred_BLSTM = np.array(list(map(lambda x: float(x+1), # Increment output to match category as np.argmax return position of one-hot array\n",
    "                        np.argmax(bi_lstm_model.predict(X_test_3dim), axis=-1))))\n",
    "print(classification_report(y_test_lstm.astype(str), y_pred_BLSTM.astype(str), target_names=target_names, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics for accuracy score under different feature extraction setting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poulating Accuracy in a histogram \n",
    "vec50_acc = [0.6245, 0.6358, 0.6965]\n",
    "vec100_acc = [0.5743, 0.6205, 0.7146]\n",
    "chi2_300f_acc = [0.6584, 0.7985, 0.7783]\n",
    "chi2_100f_acc = [0.6584, 0.7952, 0.7909]\n",
    "\n",
    "# Assmebling new DataFrame for \n",
    "hist_df = pd.DataFrame({'vec_50': np.dot(vec50_acc,100), \n",
    "                        'vec_100': np.dot(vec100_acc, 100), \n",
    "                        'chi2_300': np.dot(chi2_300f_acc, 100), \n",
    "                        'chi2_100': np.dot(chi2_100f_acc, 100)\n",
    "                        })\n",
    "hist_df = hist_df.T\n",
    "hist_df.columns = ['Naive Bayes', 'Logistic Regression', 'BLSTM']\n",
    "hist_df.head()\n",
    "# print(hist_df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(y=hist_df.iloc[0], x=hist_df.columns, name=\"vec_50\"))\n",
    "fig.add_trace(go.Bar(y=hist_df.iloc[1], x=hist_df.columns, name=\"vec_100\"))\n",
    "fig.add_trace(go.Bar(y=hist_df.iloc[2], x=hist_df.columns, name=\"chi2_300\"))\n",
    "fig.add_trace(go.Bar(y=hist_df.iloc[3], x=hist_df.columns, name=\"chi2_100\"))\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Classification Model\",\n",
    "    yaxis_title=\"Accuracy (%)\",\n",
    "    legend_title=\"Feature Extraction Type\",\n",
    "    title=\"Classification Accuracy Summary\"\n",
    ")\n",
    "\n",
    "\n",
    "fig.update_yaxes(range=[0, 100])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting label prediction to CSV files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_pred_to_csv(y_pred, fname):\n",
    "    pd.DataFrame(zip(np.arange(1, len(y_pred)+1), y_pred), columns=[\"id\", \"duration_label\"]).to_csv(\"{}\".format(fname), header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelling Linear Classifier to be used within benchmarks\n",
    "NB_clf = naive_bayes.GaussianNB()\n",
    "\n",
    "# Fit the model and name \n",
    "NB_clf.fit(X_train_name, y_train)\n",
    "y_pred_name = NB_clf.predict(X_test_name)\n",
    "\n",
    "# Fit the model and predict steps\n",
    "NB_clf.fit(X_train_steps, y_train)\n",
    "y_pred_steps = NB_clf.predict(X_test_steps)\n",
    "\n",
    "# Fit the model and predict ingredietns \n",
    "NB_clf.fit(X_train_ingr, y_train)\n",
    "y_pred_ingr = NB_clf.predict(X_test_ingr)\n",
    "\n",
    "# Package the prediction \n",
    "y_pred_NB_pool = pd.DataFrame({\"name\": y_pred_name, \"steps\": y_pred_steps, \"ingr\": y_pred_ingr})\n",
    "y_pred_NB_pool = y_pred_NB_pool.mode(axis=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelling Linear Classifier to be used within benchmarks\n",
    "LR_clf = linear_model.LogisticRegression(random_state=SEED_NO,\n",
    "                                         C=0.9, \n",
    "                                         max_iter = 50000,\n",
    "                                         multi_class='multinomial')\n",
    "# Fit the model and name \n",
    "LR_clf.fit(X_train_name, y_train)\n",
    "y_pred_name = LR_clf.predict(X_test_name)\n",
    "\n",
    "# Fit the model and predict steps\n",
    "LR_clf.fit(X_train_steps, y_train)\n",
    "y_pred_steps = LR_clf.predict(X_test_steps)\n",
    "\n",
    "# Fit the model and predict ingredietns \n",
    "LR_clf.fit(X_train_ingr, y_train)\n",
    "y_pred_ingr = LR_clf.predict(X_test_ingr)\n",
    "\n",
    "# Package the prediction \n",
    "y_pred_LR_pool = pd.DataFrame({\"name\": y_pred_name, \"steps\": y_pred_steps, \"ingr\": y_pred_ingr})\n",
    "y_pred_LR_pool = y_pred_LR_pool.mode(axis=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed X_train Dimensions:           (40000, 1, 150)\n",
      "One-hot Encoding Dimensions for y_train:  (40000, 3)\n"
     ]
    }
   ],
   "source": [
    "#Stacking all Vectorized feature and reshape them into  3-D Array\n",
    "X_train_3dim = np.hstack((X_train_ingr, X_train_name, X_train_steps))\n",
    "X_train_3dim = np.reshape(X_train_3dim, (X_train_3dim.shape[0], 1, X_train_3dim.shape[1]))\n",
    "print(\"Transformed X_train Dimensions:          \", X_train_3dim.shape)\n",
    "\n",
    "# One-hot Encoding for Y_train\n",
    "y_train_le = LabelEncoder().fit_transform(y_train)\n",
    "y_train_onehot = utils.to_categorical(y_train_le)\n",
    "print(\"One-hot Encoding Dimensions for y_train: \", y_train_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Bidirectional LSTM Classifier Report -------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0     0.6563    0.8081    0.7243      5283\n",
      "         2.0     0.7642    0.6520    0.7037      6110\n",
      "         3.0     0.6206    0.2883    0.3937       607\n",
      "\n",
      "    accuracy                         0.7023     12000\n",
      "   macro avg     0.6804    0.5828    0.6072     12000\n",
      "weighted avg     0.7094    0.7023    0.6971     12000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"------- Bidirectional LSTM Classifier Report -------\")\n",
    "y_pred_BLSTM = np.array(list(map(lambda x: float(x+1), # Increment output to match category as np.argmax return position of one-hot array\n",
    "                        np.argmax(bi_lstm_model.predict(X_test_3dim), axis=-1))))\n",
    "print(classification_report(y_test_lstm.astype(str), y_pred_BLSTM.astype(str), target_names=target_names, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_pred_to_csv(y_pred_BLSTM, \"BLSTM_y_pred_vec50.csv\")\n",
    "export_pred_to_csv(y_pred_NB_pool, \"NB_y_pred_vec50.csv\")\n",
    "export_pred_to_csv(y_pred_LR_pool, \"LR_y_pred_vec50.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "name": "python376jvsc74a57bd0dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
